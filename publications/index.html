<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | NLP@DSAI</title> <meta name="author" content=" "> <meta name="description" content="publications by categories in reversed chronological order."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="stylesheet" href="/assets/css/custom.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dsai-nlp.github.io/publications/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">NLP@DSAI</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">NLP@DSAI</a> </li> <li class="nav-item "> <a class="nav-link" href="/members">Members</a> </li> <li class="nav-item "> <a class="nav-link" href="/events">Events</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/courses/">Courses</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <article> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="audinet2025benchmarking" class="col-sm-8"> <div class="title">Benchmarking Debiasing Methods for LLM-based Parameter Estimates</div> <div class="author"> Nicolas Audinet de Pieuchon, Adel Daoud, Connor T. Jerzak, Moa Johansson, and Richard Johansson</div> <div class="periodical"> <em>arXiv preprint arXiv:2506.09627</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2506.09627" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Large language models (LLMs) offer an inexpensive yet powerful way to annotate text, but are often inconsistent when compared with experts. These errors can bias downstream estimates of population parameters such as regression coefficients and causal effects. To mitigate this bias, researchers have developed debiasing methods such as Design-based Supervised Learning (DSL) and Prediction-Powered Inference (PPI), which promise valid estimation by combining LLM annotations with a limited number of expensive expert annotations. Although these methods produce consistent estimates under theoretical assumptions, it is unknown how they compare in finite samples of sizes encountered in applied research. We make two contributions: First, we study how each method’s performance scales with the number of expert annotations, highlighting regimes where LLM bias or limited expert labels significantly affect results. Second, we compare DSL and PPI across a range of tasks, finding that although both achieve low bias with large datasets, DSL often outperforms PPI on bias reduction and empirical efficiency, but its performance is less consistent across datasets. Our findings indicate that there is a bias-variance tradeoff at the level of debiasing methods, calling for more research on developing metrics for quantifying their efficiency in finite samples.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="hagstrom2025cub" class="col-sm-8"> <div class="title">CUB: Benchmarking Context Utilisation Techniques for Language Models</div> <div class="author"> Lovisa Hagström, Youna Kim, Haeun Yu, Sang-goo Lee, Richard Johansson, Hyunsoo Cho, and Isabelle Augenstein</div> <div class="periodical"> <em>arXiv preprint arXiv:2505.16518</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2505.16518" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Incorporating external knowledge is crucial for knowledge-intensive tasks, such as question answering and fact checking. However, language models (LMs) may ignore relevant information that contradicts outdated parametric memory or be distracted by irrelevant contexts. While many context utilisation manipulation techniques (CMTs) that encourage or suppress context utilisation have recently been proposed to alleviate these issues, few have seen systematic comparison. In this paper, we develop CUB (Context Utilisation Benchmark) to help practitioners within retrieval-augmented generation (RAG) identify the best CMT for their needs. CUB allows for rigorous testing on three distinct context types, observed to capture key challenges in realistic context utilisation scenarios. With this benchmark, we evaluate seven state-of-the-art methods, representative of the main categories of CMTs, across three diverse datasets and tasks, applied to nine LMs. Our results show that most of the existing CMTs struggle to handle the full set of types of contexts that may be encountered in real-world retrieval-augmented scenarios. Moreover, we find that many CMTs display an inflated performance on simple synthesised datasets, compared to more realistic datasets with naturally occurring samples. Altogether, our results show the need for holistic tests of CMTs and the development of CMTs that can handle multiple context types.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="saynova2025fact" class="col-sm-8"> <div class="title">Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion</div> <div class="author"> Denitsa Saynova, Lovisa Hagström, Moa Johansson, Richard Johansson, and Marco Kuhlmann</div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: ACL 2025</em>, 2025 </div> <div class="periodical"> to appear </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2410.14405" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Language models (LMs) can make a correct prediction based on many possible signals in a prompt, not all corresponding to recall of factual associations. However, current interpretations of LMs fail to take this into account. For example, given the query "Astrid Lindgren was born in" with the corresponding completion "Sweden", no difference is made between whether the prediction was based on knowing where the author was born or assuming that a person with a Swedish-sounding name was born in Sweden. In this paper, we present a model-specific recipe - PrISM - for constructing datasets with examples of four different prediction scenarios: generic language modeling, guesswork, heuristics recall and exact fact recall. We apply two popular interpretability methods to the scenarios: causal tracing (CT) and information flow analysis. We find that both yield distinct results for each scenario. Results for exact fact recall and generic language modeling scenarios confirm previous conclusions about the importance of mid-range MLP sublayers for fact recall, while results for guesswork and heuristics indicate a critical role of late last token position MLP sublayers. In summary, we contribute resources for a more extensive and granular study of fact completion in LMs, together with analyses that provide a more nuanced understanding of how LMs process fact-related queries.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="hagstrom2025reality" class="col-sm-8"> <div class="title">A Reality Check on Context Utilisation for Retrieval-Augmented Generation </div> <div class="author"> Lovisa Hagström, Sara Vera Marjanović, Haeun Yu, Arnav Arora, Christina Lioma, Maria Maistro, Pepa Atanasova, and Isabelle Augenstein</div> <div class="periodical"> <em>In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics</em>, 2025 </div> <div class="periodical"> to appear </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2412.17031" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Retrieval-augmented generation (RAG) helps address the limitations of the parametric knowledge embedded within a language model (LM). However, investigations of how LMs utilise retrieved information of varying complexity in real-world scenarios have been limited to synthetic contexts. We introduce DRUID (Dataset of Retrieved Unreliable, Insufficient and Difficult-to-understand contexts) with real-world queries and contexts manually annotated for stance. The dataset is based on the prototypical task of automated claim verification, for which automated retrieval of real-world evidence is crucial. We compare DRUID to synthetic datasets (CounterFact, ConflictQA) and find that artificial datasets often fail to represent the complex and diverse real-world context settings. We show that synthetic datasets exaggerate context characteristics rare in real retrieved data, which leads to inflated context utilisation results, as measured by our novel ACU score. Moreover, while previous work has mainly focused on singleton context characteristics to explain context utilisation, correlations between singleton context properties and ACU on DRUID are surprisingly small compared to other properties related to context source. Overall, our work underscores the need for real-world aligned context utilisation studies to represent and improve performance in real-world RAG settings.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="hagstrom2025rerankers" class="col-sm-8"> <div class="title">Language Model Re-rankers are Steered by Lexical Similarities</div> <div class="author"> Lovisa Hagström, Ercong Nie, Ruben Halifa, Helmut Schmid, Richard Johansson, and Alexander Junge</div> <div class="periodical"> <em>arXiv preprint arXiv:2502.17036</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2502.17036" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Language model (LM) re-rankers are used to refine retrieval results for retrieval-augmented generation (RAG). They are more expensive than lexical matching methods like BM25 but assumed to better process semantic information. To understand whether LM re-rankers always live up to this assumption, we evaluate 6 different LM re-rankers on the NQ, LitQA2 and DRUID datasets. Our results show that LM re-rankers struggle to outperform a simple BM25 re-ranker on DRUID. Leveraging a novel separation metric based on BM25 scores, we explain and identify re-ranker errors stemming from lexical dissimilarities. We also investigate different methods to improve LM re-ranker performance and find these methods mainly useful for NQ. Taken together, our work identifies and explains weaknesses of LM re-rankers and points to the need for more adversarial and realistic datasets for their evaluation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="saynova2025identifying" class="col-sm-8"> <div class="title">Identifying Non-Replicable Social Science Studies with Language Models</div> <div class="author"> Denitsa Saynova, Kajsa Hansson, Bastiaan Bruinsma, Annika Fredén, and Moa Johansson</div> <div class="periodical"> <em>arXiv preprint arXiv:2503.10671</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/pdf/2503.10671" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>In this study, we investigate whether LLMs can be used to indicate if a study in the behavioural social sciences is replicable. Using a dataset of 14 previously replicated studies (9 successful, 5 unsuccessful), we evaluate the ability of both open-source (Llama 3 8B, Qwen 2 7B, Mistral 7B) and proprietary (GPT-4o) instruction-tuned LLMs to discriminate between replicable and non-replicable findings. We use LLMs to generate synthetic samples of responses from behavioural studies and estimate whether the measured effects support the original findings. When compared with human replication results for these studies, we achieve F1 values of up to 77% with Mistral 7B, 67% with GPT-4o and Llama 3 8B, and 55% with Qwen 2 7B, suggesting their potential for this task. We also analyse how effect size calculations are affected by sampling temperature and find that low variance (due to temperature) leads to biased effect estimates.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="pnfs2025" class="col-sm-8"> <div class="title">From Electrophoresis to Wikidata: Festschrift in honor of Pierre Nugues</div> <div class="author"> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://hdl.handle.net/10062/109655" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="johansson2025exhuming" class="col-sm-8"> <div class="title">Exhuming a Swedish Temporal Relation Dataset from the Past</div> <div class="author"> Richard Johansson</div> <div class="periodical"> <em>In From Electrophoresis to Wikidata: Festschrift in honor of Pierre Nugues</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://hdl.handle.net/10062/109659" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>I resurrected a dataset containing annotated event-to-event temporal relations in Swedish traffic accident reports, and then benchmarked how well contemporary large language models classify these relations. Can the current generation of LLMs outperform our results from two decades ago?</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="farahani2024deciphering" class="col-sm-8"> <div class="title">Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models</div> <div class="author"> Mehrdad Farahani, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2024.emnlp-main.943.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Generative language models often struggle with specialized or less-discussed knowledge. A potential solution is found in Retrieval-Augmented Generation (RAG) models which act like retrieving information before generating responses. In this study, we explore how the Atlas approach, a RAG model, decides between what it already knows (parametric) and what it retrieves (non-parametric). We use causal mediation analysis and controlled experiments to examine how internal representations influence information processing. Our findings disentangle the effects of parametric knowledge and the retrieved context. They indicate that in cases where the model can choose between both types of information (parametric and non-parametric), it relies more on the context than the parametric knowledge. Furthermore, the analysis investigates the computations involved in \textithow the model uses the information from the context. We find that multiple mechanisms are active within the model and can be detected with mediation analysis: first, the decision of \textitwhether the context is relevant, and second, how the encoder computes output representations to support copying when relevant.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="audinet2024can" class="col-sm-8"> <div class="title">Can Large Language Models (or Humans) Disentangle Text?</div> <div class="author"> Nicolas Audinet Pieuchon, Adel Daoud, Connor Jerzak, Moa Johansson, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 6th Workshop on Natural Language Processing and Computational Social Science (NLP+CSS)</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2024.nlpcss-1.5.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We investigate the potential of large language models (LLMs) to disentangle text variables–to remove the textual traces of an undesired forbidden variable in a task sometimes known as text distillation and closely related to the fairness in AI and causal inference literature. We employ a range of various LLM approaches in an attempt to disentangle text by identifying and removing information about a target variable while preserving other relevant signals. We show that in the strong test of removing sentiment, the statistical association between the processed text and sentiment is still detectable to machine learning classifiers post-LLM-disentanglement. Furthermore, we find that human annotators also struggle to disentangle sentiment while preserving other semantic content. This suggests there may be limited separability between concept variables in some text contexts, highlighting limitations of methods relying on text-level transformations and also raising questions about the robustness of disentanglement methods that achieve statistical independence in representation space.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="bruinsma2024setting" class="col-sm-8"> <div class="title">Setting the AI Agenda – Evidence from Sweden in the ChatGPT Era</div> <div class="author"> Bastiaan Bruinsma, Annika Fredén, Kajsa Hansson, Moa Johansson, Pasko Kisić-Merino, and Denitsa Saynova</div> <div class="periodical"> <em>In Proceedings of AEQUITAS 2024: Workshop on Fairness and Bias in AI</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ceur-ws.org/Vol-3808/paper1.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This paper examines the development of the Artificial Intelligence (AI) meta-debate in Sweden before and after the release of ChatGPT. From the perspective of agenda-setting theory, we propose that it is an elite outside of party politics that is leading the debate – i.e. that the politicians are relatively silent when it comes to this rapid development. We also suggest that the debate has become more substantive and risk-oriented in recent years. To investigate this claim, we draw on an original dataset of elite-level documents from the early 2010s to the present, using op-eds published in a number of leading Swedish newspapers. By conducting a qualitative content analysis of these materials, our preliminary findings lend support to the expectation that an academic, rather than a political elite is steering the debate.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="freden2024word" class="col-sm-8"> <div class="title">Word embeddings on ideology and issues from Swedish parliamentarians’ motions: a comparative approach</div> <div class="author"> Annika Fredén, Moa Johansson, and Denitsa Saynova</div> <div class="periodical"> <em>Journal of Elections, Public Opinion and Parties</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1080/17457289.2024.2433979" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="johansson2024what" class="col-sm-8"> <div class="title">What Happens to a Dataset Transformed by a Projection-based Concept Removal Method?</div> <div class="author"> Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2024.lrec-main.1520.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We investigate the behavior of methods that use linear projections to remove information about a concept from a language representation, and we consider the question of what happens to a dataset transformed by such a method. A theoretical analysis and experiments on real-world and synthetic data show that these methods inject strong statistical dependencies into the transformed datasets. After applying such a method, the representation space is highly structured: in the transformed space, an instance tends to be located near instances of the opposite label. As a consequence, the original labeling can in some cases be reconstructed by applying an anti-clustering method.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="hagstrom-etal-2023-effect" class="col-sm-8"> <div class="title">The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models</div> <div class="author"> Lovisa Hagström, Denitsa Saynova, Tobias Norlund, Moa Johansson, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.emnlp-main.332.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Large Language Models (LLMs) make natural interfaces to factual knowledge, but their usefulness is limited by their tendency to deliver inconsistent answers to semantically equivalent questions. For example, a model might supply the answer “Edinburgh” to “Anne Redpath passed away in X.” and “London” to “Anne Redpath’s life ended in X.” In this work, we identify potential causes of inconsistency and evaluate the effectiveness of two mitigation strategies: up-scaling and augmenting the LM with a passage retrieval database. Our results on the LLaMA and Atlas models show that both strategies reduce inconsistency but that retrieval augmentation is considerably more efficient. We further consider and disentangle the consistency contributions of different components of Atlas. For all LMs evaluated we find that syntactical form and task artifacts impact consistency. Taken together, our results provide a better understanding of the factors affecting the factual consistency of language models.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="doostmohammadi-etal-2023-surface" class="col-sm-8"> <div class="title">Surface-Based Retrieval Reduces Perplexity of Retrieval-Augmented Language Models</div> <div class="author"> Ehsan Doostmohammadi, Tobias Norlund, Marco Kuhlmann, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.acl-short.45.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Augmenting language models with a retrieval mechanism has been shown to significantly improve their performance while keeping the number of parameters low. Retrieval-augmented models commonly rely on a semantic retrieval mechanism based on the similarity between dense representations of the query chunk and potential neighbors. In this paper, we study the state-of-the-art Retro model and observe that its performance gain is better explained by surface-level similarities, such as token overlap. Inspired by this, we replace the semantic retrieval in Retro with a surface-level method based on BM25, obtaining a significant reduction in perplexity. As full BM25 retrieval can be computationally costly for large datasets, we also apply it in a re-ranking scenario, gaining part of the perplexity reduction with minimal computational overhead.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="bonafilia2023sudden" class="col-sm-8"> <div class="title">Sudden Semantic Shifts in Swedish NATO discourse</div> <div class="author"> Brian Bonafilia, Bastiaan Bruinsma, Denitsa Saynova, and Moa Johansson</div> <div class="periodical"> <em>In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.acl-srw.28.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>In this paper, we investigate a type of semantic shift that occurs when a sudden event radically changes public opinion on a topic. Looking at Sweden‘s decision to apply for NATO membership in 2022, we use word embeddings to study how the associations users on Twitter have regarding NATO evolve. We identify several changes that we successfully validate against real-world events. However, the low engagement of the public with the issue often made it challenging to distinguish true signals from noise. We thus find that domain knowledge and data selection are of prime importance when using word embeddings to study semantic shifts.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="norlund-etal-2023-generalization" class="col-sm-8"> <div class="title">On the Generalization Ability of Retrieval-Enhanced Transformers</div> <div class="author"> Tobias Norlund, Ehsan Doostmohammadi, Richard Johansson, and Marco Kuhlmann</div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: EACL 2023</em>, May 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.findings-eacl.109.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Recent work on the Retrieval-Enhanced Transformer (RETRO) model has shown impressive results: off-loading memory from trainable weights to a retrieval database can significantly improve language modeling and match the performance of non-retrieval models that are an order of magnitude larger in size. It has been suggested that at least some of this performance gain is due to non-trivial generalization based on both model weights and retrieval. In this paper, we try to better understand the relative contributions of these two components. We find that the performance gains from retrieval to a very large extent originate from overlapping tokens between the database and the test data, suggesting less of non-trivial generalization than previously assumed. More generally, our results point to the challenges of evaluating the generalization of retrieval-augmented language models such as RETRO, as even limited token overlap may significantly decrease test-time loss. We release our code and model at \urlhttps://github.com/TobiasNorlund/retro</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="farahani-johansson-2023-empirical" class="col-sm-8"> <div class="title">An Empirical Study of Multitask Learning to Improve Open Domain Dialogue Systems</div> <div class="author"> Mehrdad Farahani, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)</em>, May 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.nodalida-1.36.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Autoregressive models used to generate responses in open-domain dialogue systems often struggle to take long-term context into account and to maintain consistency over a dialogue. Previous research in open-domain dialogue generation has shown that the use of \textitauxiliary tasks can introduce inductive biases that encourage the model to improve these qualities. However, most previous research has focused on encoder-only or encoder/decoder models, while the use of auxiliary tasks in \textitencoder-only autoregressive models is under-explored. This paper describes an investigation where four different auxiliary tasks are added to small and medium-sized GPT-2 models fine-tuned on the PersonaChat and DailyDialog datasets. The results show that the introduction of the new auxiliary tasks leads to small but consistent improvement in evaluations of the investigated models.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="saynova-etal-2023-class" class="col-sm-8"> <div class="title">Class Explanations: the Role of Domain-Specific Content and Stop Words</div> <div class="author"> Denitsa Saynova, Bastiaan Bruinsma, Moa Johansson, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)</em>, May 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2023.nodalida-1.12.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We address two understudied areas related to explainability for neural text models. First, \textitclass explanations. What features are descriptive across a class, rather than explaining single input instances? Second, the \textittype of features that are used for providing explanations. Does the explanation involve the statistical pattern of word usage or the presence of domain-specific content words? Here, we present a method to extract both class explanations and strategies to differentiate between two types of explanations – domain-specific signals or statistical variations in frequencies of common words. We demonstrate our method using a case study in which we analyse transcripts of political debates in the Swedish Riksdag.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="malik2022" class="col-sm-8"> <div class="title">Controlling for Stereotypes in Multimodal Language Model Evaluation</div> <div class="author"> Manuj Malik, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="johansson2022" class="col-sm-8"> <div class="title">Coveting Your Neighbor’s Wife: Using Lexical Neighborhoods in Substitution-based Word Sense Disambiguation</div> <div class="author"> Richard Johansson</div> <div class="periodical"> <em>In LIVE and LEARN – Festschrift in honor of Lars Borin</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://gupea.ub.gu.se/handle/2077/74254" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="raj2022" class="col-sm-8"> <div class="title">Cross-modal Transfer Between Vision and Language for Protest Detection</div> <div class="author"> Ria Raj, Kajsa Andéasson, Tobias Norlund, Richard Johansson, and Aron Lagerberg</div> <div class="periodical"> <em>In Proceedings of the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE)</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2022.case-1.8.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="hagstrom2022c" class="col-sm-8"> <div class="title">Can We Use Small Models to Investigate Multimodal Fusion Methods?</div> <div class="author"> Lovisa Hagström, Tobias Norlund, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 2022 CLASP Conference on (Dis)embodiment</em>, Sep 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2022.clasp-1.5.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="daoud2022" class="col-sm-8"> <div class="title">Conceptualizing Treatment Leakage in Text-based Causal Inference</div> <div class="author"> Adel Daoud, Connor Jerzak, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, Jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2022.naacl-main.413.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="hagstrom2022a" class="col-sm-8"> <div class="title">What do Models Learn From Training on More Than Text? Measuring Visual Commonsense Knowledge</div> <div class="author"> Lovisa Hagström, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</em>, May 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2022.acl-srw.19.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="hagstrom2022b" class="col-sm-8"> <div class="title">How to Adapt Pre-trained Vision-and-Language Models to a Text-only Input?</div> <div class="author"> Lovisa Hagström, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 29th International Conference on Computational Linguistics (COLING)</em>, May 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2022.coling-1.494.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="hagberg2022" class="col-sm-8"> <div class="title">Semi-supervised Learning with Natural Language Processing for Right Ventricle Classification in Echocardiography – a Scalable Approach</div> <div class="author"> Eva Hagberg, David Hagerman, Richard Johansson, Nasser Hosseini, Jan Liu, Elin Björnsson, Jennifer Alvén, and Ola Hjelmgren</div> <div class="periodical"> <em>Computers in Biology and Medicine</em>, May 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.sciencedirect.com/science/article/pii/S0010482522000749" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="norlund2021" class="col-sm-8"> <div class="title">Transferring Knowledge from Vision to Language: How to Achieve it and how to Measure it?</div> <div class="author"> Tobias Norlund, Lovisa Hagström, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</em>, May 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2021.blackboxnlp-1.10.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="hagstrom2021" class="col-sm-8"> <div class="title">Knowledge Distillation for Swedish NER models: A Search for Performance and Efficiency</div> <div class="author"> Lovisa Hagström, and Richard Johansson</div> <div class="periodical"> <em>In Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa 2021)</em>, May 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://www.aclweb.org/anthology/2021.nodalida-main.13.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>