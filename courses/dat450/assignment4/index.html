<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>DAT450/DIT247: Programming Assignment 4: Supervised Fine-Tuning (SFT) with LoRA | NLP@DSAI</title> <meta name="author" content=" "> <meta name="description" content="NLP@DSAI is a constellation of researchers who carry out foundational or applied research in natural language processing (NLP), or are interested in NLP techniques generally. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="stylesheet" href="/assets/css/custom.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dsai-nlp.github.io/courses/dat450/assignment4/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">NLP@DSAI</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">NLP@DSAI</a> </li> <li class="nav-item "> <a class="nav-link" href="/members">Members</a> </li> <li class="nav-item "> <a class="nav-link" href="/events">Events</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">News</a> </li> <li class="nav-item "> <a class="nav-link" href="/courses/">Courses</a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <article> <h1 id="dat450dit247-programming-assignment-4-supervised-fine-tuning-sft-with-lora">DAT450/DIT247: Programming Assignment 4: Supervised Fine-Tuning (SFT) with LoRA</h1> <p>In this assignment, you will perform supervised fine-tuning (SFT) of a small open LLM (preferably <a href="https://huggingface.co/allenai/OLMo-2-0425-1B" rel="external nofollow noopener" target="_blank">OLMo-2 1B</a>) on <a href="https://huggingface.co/datasets/tatsu-lab/alpaca" rel="external nofollow noopener" target="_blank">Alpaca</a>, a dataset of 52k instructions generated by OpenAI’s text-davinci-003 engine. You will convert this dataset into instruction-response pairs, fine-tune a causal language model using LoRA (Low-Rank Adaptation), and evaluate it through prompted inference and comparison with other methods.</p> <h3 id="pedagogical-purposes-of-this-assignment">Pedagogical purposes of this assignment</h3> <ul> <li>You will see how the metric and computational efficiency are affected by the different fine-tuning methods.</li> <li>Learn and apply LoRA for parameter-efficient tuning of causal LMs.</li> <li>You will learn more about what instruction tuning is and how the model deals with it during training.</li> <li>You will get some additional practical experience of working with HuggingFace libraries, which provide useful utilities for preprocessing and training.</li> </ul> <h3 id="requirements">Requirements</h3> <p>Please submit your solution <a href="https://canvas.chalmers.se/courses/36909/assignments/117618" rel="external nofollow noopener" target="_blank">in Canvas</a>. <strong>Submission deadline: December 1</strong>.</p> <p>Submit Python files containing your solution to the programming tasks described below. In addition, to save time for the people who grade your submission, please submit a text file containing the outputs printed out by your Python program; read the instructions carefully so that the right outputs are included. The most important outputs are already designed for the code.</p> <p>This is a pure programming assignment and you do not have to write a technical report or explain details of your solution: there will be a separate individual assignment where you will answer some conceptual questions about what you have been doing here.</p> <h3 id="acknowledgement">Acknowledgement</h3> <p>This assignment is adapted from a previous version by Marco Kuhlmann and updated to SFT with LoRA for a small LLM.</p> <h2 id="step-0-preliminaries">Step 0: Preliminaries</h2> <h3 id="libraries">Libraries</h3> <p>As in the previous assignments, you can use the pre-set environment <code class="language-plaintext highlighter-rouge">source /data/courses/2025_dat450_dit247/venvs/dat450_venv/bin/activate</code>.</p> <p>Alternatively, if you are working on your own machine or some cloud-based service, install the following libraries with a package manager such as <code class="language-plaintext highlighter-rouge">pip</code> or <code class="language-plaintext highlighter-rouge">uv</code>:</p> <ul> <li><a href="https://docs.pytorch.org/docs/stable/index.html" rel="external nofollow noopener" target="_blank">Torch</a></li> <li><a href="https://huggingface.co/docs/transformers/index" rel="external nofollow noopener" target="_blank">Transformers</a></li> <li><a href="https://huggingface.co/docs/datasets/index" rel="external nofollow noopener" target="_blank">Datasets</a></li> <li><a href="https://huggingface.co/docs/evaluate/en/index" rel="external nofollow noopener" target="_blank">Evaluate</a></li> <li><a href="https://www.nltk.org/api/nltk.html" rel="external nofollow noopener" target="_blank">NLTK</a></li> </ul> <h3 id="getting-the-files">Getting the files</h3> <p>The dataset <a href="https://huggingface.co/datasets/tatsu-lab/alpaca" rel="external nofollow noopener" target="_blank">Alpaca</a> is a collection of 52k instruction-response pairs designed for SFT of LLM for instruction following (JSON format). You can load using the HF datasets as:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="n">alpaca_dataset</span> <span class="o">=</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="sh">"</span><span class="s">/data/courses/2025_dat450_dit247/datasets/alpaca-cleaned</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <details> <summary><b>Hint</b>: Output...</summary> <div style="margin-left: 10px; border-radius: 4px; background: #fff; border: 1px solid black; padding: 10px;"> <pre>
DatasetDict({
    train: Dataset({
        features: ['instruction', 'input', 'output'],
        num_rows: 51760
    })
})
</pre> </div> </details> <p>Since these 52k data points make fine-tuning longer, for simplicity in this course, we only consider 2K + 200 samples for training and testing. Of course, during learning, you can use a smaller amount to ensure your implementation works properly. For the final submission, go ahead with 2K + 200 samples and use the same seed as the code scaffold, <code class="language-plaintext highlighter-rouge">SEED=101</code>, to help TAs evaluate your outputs.</p> <p>To get a clear idea of how to complete the assignment, you can start with the skeleton code available here: <code class="language-plaintext highlighter-rouge">/data/courses/2025_dat450_dit247/assignments/a4</code>. It looks like this:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">.</span>
├── data_utils.py
├── inference.sh
├── lora.py
├── main.py
├── predict.py
├── run.sh
└── utils.py
</code></pre></div></div> <p>In short, you need to fill in the incomplete parts of <code class="language-plaintext highlighter-rouge">data_utils.py</code> and <code class="language-plaintext highlighter-rouge">lora.py</code>. The other files contain helpful functions to run the assignment. It’s highly recommended to review the documented code to understand the structure of the project. To ensure your code works correctly, you can follow these instructions and run the code using the pre-built environment:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 main.py
</code></pre></div></div> <h2 id="step-1-preprocessing">Step 1: Preprocessing</h2> <p>Create a Dataset by loading Alpaca training set that already downloaded for you.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="n">alpaca_dataset</span> <span class="o">=</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="sh">"</span><span class="s">/data/courses/2025_dat450_dit247/datasets/alpaca-cleaned</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <details> <summary><b>Hint</b>: Output...</summary> <div style="margin-left: 10px; border-radius: 4px; background: #fff; border: 1px solid black; padding: 10px;"> <pre>
DatasetDict({
    train: Dataset({
        features: ['instruction', 'input', 'output'],
        num_rows: 51760
    })
})
</pre> </div> </details> <p>Then we need to create our training and testing sets from that dataset. To do this, we use two methods provided by HF datasets, <a href="https://huggingface.co/docs/datasets/v1.8.0/package_reference/main_classes.html#datasets.Dataset.select" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">select</code></a> and <a href="https://huggingface.co/docs/datasets/v1.8.0/package_reference/main_classes.html#datasets.Dataset.train_test_split" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">train_test_split</code></a>, which help us choose the subsets as training and testing data. Although we provide a cleaned version of Alpaca, we need to filter out all rows where the output is empty to ensure we always have output. To achieve an equal distribution of different instructions corresponding to the inputs, we also stratify the rows based on the presence or absence of input.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="n">utils</span> <span class="kn">import</span> <span class="n">create_stratification_label</span>

<span class="n">alpaca_dataset</span> <span class="o">=</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="sh">"</span><span class="s">/data/courses/2025_dat450_dit247/datasets/alpaca-cleaned</span><span class="sh">"</span><span class="p">)</span>

<span class="n">alpaca_dataset</span><span class="p">[</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpaca_dataset</span><span class="p">[</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">].</span><span class="nf">filter</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">x</span><span class="p">[</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">].</span><span class="nf">strip</span><span class="p">()</span> <span class="o">!=</span> <span class="sh">""</span>
<span class="p">)</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">alpaca_dataset</span><span class="p">[</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">create_stratification_label</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">columns_to_check</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">input</span><span class="sh">"</span><span class="p">])</span>
<span class="p">)</span>
<span class="c1"># Turn strat_label into a ClassLabel so we can stratify
</span><span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="nf">class_encode_column</span><span class="p">(</span><span class="sh">"</span><span class="s">strat_label</span><span class="sh">"</span><span class="p">)</span>

<span class="n">ds</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ds</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    <span class="p">.</span><span class="nf">select</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">MAX_TRAIN_SAMPLES</span> <span class="o">+</span> <span class="n">MAX_TEST_SAMPLES</span><span class="p">))</span>
    <span class="p">.</span><span class="nf">train_test_split</span><span class="p">(</span>
        <span class="n">train_size</span><span class="o">=</span><span class="n">MAX_TRAIN_SAMPLES</span><span class="p">,</span>
        <span class="n">test_size</span><span class="o">=</span><span class="n">MAX_TEST_SAMPLES</span><span class="p">,</span>
        <span class="n">stratify_by_column</span><span class="o">=</span><span class="sh">"</span><span class="s">strat_label</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div> <details> <summary><b>Hint</b>: Output...</summary> <div style="margin-left: 10px; border-radius: 4px; background: #fff; border: 1px solid black; padding: 10px;"> <pre>
ALPACA DATASET:
DatasetDict({
    train: Dataset({
        features: ['output', 'input', 'instruction'],
        num_rows: 51760
    })
})

ALPACA + SUBSAMPLE:
DatasetDict({
    train: Dataset({
        features: ['output', 'input', 'instruction', 'strat_label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['output', 'input', 'instruction', 'strat_label'],
        num_rows: 400
    })
})
</pre> </div> </details> <p>And finally, we need to construct our LLM input as prompts and output as labels.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">data_utils</span> <span class="kn">import</span> <span class="n">build_prompt</span>

<span class="n">PROMPT_NO_INPUT</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">
Below is an instruction that describes a task. 
Write a response that appropriately completes the request.

### Instruction:
{instruction}

### Response:
</span><span class="sh">"""</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>

<span class="n">PROMPT_WITH_INPUT</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">
Below is an instruction that describes a task, paired with an input that provides further context. 
Write a response that appropriately completes the request.

### Instruction:
{instruction}

### Input:
{input}

### Response:
</span><span class="sh">"""</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>

<span class="n">ds_sft</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">build_prompt</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">PROMPT_NO_INPUT</span><span class="p">,</span> <span class="n">PROMPT_WITH_INPUT</span><span class="p">))</span>
</code></pre></div></div> <details> <summary><b>Hint</b>: Output...</summary> <div style="margin-left: 10px; border-radius: 4px; background: #fff; border: 1px solid black; padding: 10px;"> <pre>
Sample with prompt:
{
  "output": "D) \"You're great.\"",
  "input": "What do you think of me?\n\nA) \"You're annoying.\"\nB) \"I don't know you.\"\nC) \"You're cool.\"\nD) \"You're great.\"",
  "instruction": "Select the most optimal response.",
  "strat_label": 1,
  "prompt": "Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request.\n\n### Instruction:\nSelect the most optimal response.\n\n### Input:\nWhat do you think of me?\n\nA) \"You're annoying.\"\nB) \"I don't know you.\"\nC) \"You're cool.\"\nD) \"You're great.\"\n\n### Response:",
  "answer": "D) \"You're great.\""
}
</pre> </div> </details> <p>Pre-trained LLMs are simply autoregressive models (next-token predictors); they learn patterns in text, not how to follow instructions. Therefore, SFT can enhance LLMs by teaching them how to answer tasks directly, structure their outputs, respond helpfully, and more. In real commercial systems like ChatGPT, Claude, and others, instruction tuning followed by reinforcement learning are crucial steps that make the models more practically useful. As mentioned before, Alpaca serves as a starting point to help our simple LLM (OLMo) adopt similar features. To achieve this, we define some templates based on the presence or absence of input for the Alpaca dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="n">datasets</span> <span class="kn">import</span> <span class="n">DatasetDict</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">MODEL_NAME_OR_PATH</span><span class="p">)</span>
<span class="k">if</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
    <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">eos_token</span> <span class="ow">or</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">unk_token</span>

<span class="n">tokenized_ds_sft</span> <span class="o">=</span> <span class="nc">DatasetDict</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">:</span> <span class="n">ds_sft</span><span class="p">[</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">tokenize_helper</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">)),</span>
        <span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">:</span> <span class="n">ds_sft</span><span class="p">[</span><span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">tokenize_helper</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">MAX_LENGTH</span><span class="p">)),</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">data_collator</span> <span class="o">=</span> <span class="nf">create_data_collator</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
</code></pre></div></div> <details> <summary><b>Hint</b>: Output...</summary> <div style="margin-left: 10px; border-radius: 4px; background: #fff; border: 1px solid black; padding: 10px;"> <pre>
TOKENIZED DATASET:
DatasetDict({
    train: Dataset({
        features: ['output', 'input', 'instruction', 'strat_label', 'prompt', 'answer', 'input_ids', 'attention_mask', 'labels'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['output', 'input', 'instruction', 'strat_label', 'prompt', 'answer', 'input_ids', 'attention_mask', 'labels'],
        num_rows: 400
    })
})
</pre> </div> </details> <h2 id="step-2-baseline-zero-shot-and-prompt-format">Step 2: Baseline zero-shot and prompt format</h2> <p>Set MODEL_NAME_OR_PATH (default suggested: <code class="language-plaintext highlighter-rouge">/data/courses/2025_dat450_dit247/models/OLMo-2-0425-1B</code>). Load the tokenizer and model in causal LM form.</p> <p>Then we will see how OLMo, as a simple pre-trained LLM that has no understanding of how instructions work, responds to some instruction prompt, and we will compute the <a href="https://aclanthology.org/W04-1013.pdf" rel="external nofollow noopener" target="_blank">ROUGE-L</a> metric for this and subsequent models. Since the Alpaca has the output for each pair of instruction and input, we can use that output as a reference to compute the ROUGE-L metric, which will give us a measure of how well the model captures whether it produces the same key ideas and structure, even if the exact wording differs.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>
<span class="kn">from</span> <span class="n">utils</span> <span class="kn">import</span> <span class="n">make_trainer</span><span class="p">,</span> <span class="n">RougeMetricComputer</span>


<span class="n">compute_metrics</span> <span class="o">=</span> <span class="nc">RougeMetricComputer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>

<span class="n">pretrained_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">MODEL_NAME_OR_PATH</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="n">pretrained_eval_args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sh">"</span><span class="s">pretrained</span><span class="sh">"</span><span class="p">),</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">no</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">fp16</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">(),</span>
    <span class="n">report_to</span><span class="o">=</span><span class="sh">"</span><span class="s">none</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">batch_eval_metrics</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">eval_accumulation_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">pretrained_trainer</span> <span class="o">=</span> <span class="nf">make_trainer</span><span class="p">(</span>
    <span class="n">pretrained_model</span><span class="p">,</span>
    <span class="n">pretrained_eval_args</span><span class="p">,</span>
    <span class="n">tokenized_ds_sft</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="p">,</span>
    <span class="n">data_collator</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">perf_counter</span><span class="p">()</span>
<span class="n">pretrained_eval_metrics</span> <span class="o">=</span> <span class="n">pretrained_trainer</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">()</span>
<span class="n">pretrained_eval_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>

<span class="n">pretrained_eval_loss</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">pretrained_eval_metrics</span><span class="p">[</span><span class="sh">"</span><span class="s">eval_loss</span><span class="sh">"</span><span class="p">])</span>
<span class="n">pretrained_rougeL</span> <span class="o">=</span> <span class="n">pretrained_eval_metrics</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">eval_rougeL</span><span class="sh">"</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</code></pre></div></div> <details> <summary><b>Hint</b>: Output...</summary> <div style="margin-left: 10px; border-radius: 4px; background: #fff; border: 1px solid black; padding: 10px;"> <pre>
PRETRAINED EVAL METRICS:
{
  "eval_loss": 1.4962108135223389,
  "eval_model_preparation_time": 0.0023,
  "eval_rougeL": 0.6029353987530564,
  "eval_runtime": 36.4135,
  "eval_samples_per_second": 10.985,
  "eval_steps_per_second": 10.985
}
</pre> </div> </details> <h3 id="counting-the-number-of-trainable-parameters">Counting the number of trainable parameters</h3> <p>Define a function <code class="language-plaintext highlighter-rouge">num_trainable_parameters</code> that computes the number of floating-point numbers that a given model will update during training.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">num_trainable_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Count number of trainable parameters (requires_grad=True).</span><span class="sh">"""</span>
    <span class="k">return</span> <span class="nf">sum</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="nf">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>The methods <code class="language-plaintext highlighter-rouge">.parameters()</code> and <code class="language-plaintext highlighter-rouge">.named_parameters()</code> return a sequence of tensors containing the model parameters.</li> <li>When counting the <strong>trainable</strong> parameters, you should only include those tensors where <code class="language-plaintext highlighter-rouge">requires_grad</code> is <code class="language-plaintext highlighter-rouge">True</code>. That is: we want to exclude tensors containing parameters we will not update during training.</li> </ul> <p><strong>Sanity check</strong>: The number of trainable parameters for the model above should be 1484916736.</p> <h3 id="preparing-for-training">Preparing for training</h3> <p>The class <code class="language-plaintext highlighter-rouge">TrainingArguments</code> defines some parameters controlling the training process. We’ll mostly use default values here. You only need to set the following parameters:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">output_dir</code>: the name of some directory where the <code class="language-plaintext highlighter-rouge">Trainer</code> will keep its file.</li> <li> <code class="language-plaintext highlighter-rouge">num_train_epochs</code>: the number of training epochs.</li> <li> <code class="language-plaintext highlighter-rouge">eval_strategy</code>: set this to <code class="language-plaintext highlighter-rouge">epoch</code> to see evaluation scores after each epoch.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>


<span class="n">pretrained_eval_args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sh">"</span><span class="s">pretrained</span><span class="sh">"</span><span class="p">),</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">no</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">fp16</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">(),</span>
    <span class="n">report_to</span><span class="o">=</span><span class="sh">"</span><span class="s">none</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">batch_eval_metrics</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">eval_accumulation_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div> <p>In addition, we need to define a helper function that will be used for evaluation after each epoch. We use a utility from the Evaluate library for this:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">utils</span> <span class="kn">import</span> <span class="n">RougeMetricComputer</span>

<span class="n">compute_metrics</span> <span class="o">=</span> <span class="nc">RougeMetricComputer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
</code></pre></div></div> <h3 id="training-the-model">Training the model</h3> <p>Import <code class="language-plaintext highlighter-rouge">Trainer</code> from the <code class="language-plaintext highlighter-rouge">transformers</code> library. Create a <code class="language-plaintext highlighter-rouge">Trainer</code> using the following arguments:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">model</code>: the model that you are fine-tuning;</li> <li> <code class="language-plaintext highlighter-rouge">args</code>: the training arguments you defined above;</li> <li> <code class="language-plaintext highlighter-rouge">train_dataset</code>: the <code class="language-plaintext highlighter-rouge">train</code> section of your tokenized <code class="language-plaintext highlighter-rouge">Dataset</code>;</li> <li> <code class="language-plaintext highlighter-rouge">eval_dataset</code>: the <code class="language-plaintext highlighter-rouge">eval</code> section of your tokenized <code class="language-plaintext highlighter-rouge">Dataset</code>;</li> <li> <code class="language-plaintext highlighter-rouge">compute_metrics</code>: the evaluation helper function you defined above.</li> </ul> <p>Run the fine-tuning process by calling <code class="language-plaintext highlighter-rouge">train()</code> on your <code class="language-plaintext highlighter-rouge">Trainer</code>. This will train for the specified number of epochs, computing loss and accuracy after each epoch.</p> <p>After training, you may call <code class="language-plaintext highlighter-rouge">save_model</code> on the <code class="language-plaintext highlighter-rouge">Trainer</code> to save the model’s parameters. In this way, you can reload it later without having to retrain it.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>


<span class="k">def</span> <span class="nf">make_trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">training_args</span><span class="p">,</span> <span class="n">tokenized_ds_sft</span><span class="p">,</span> <span class="n">compute_metrics</span><span class="p">,</span> <span class="n">data_collator</span>
<span class="p">):</span>
    <span class="sh">"""</span><span class="s">Create a Trainer for SFT on tokenized_ds_sft.</span><span class="sh">"""</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">tokenized_ds_sft</span><span class="p">[</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">],</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">tokenized_ds_sft</span><span class="p">[</span><span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">],</span>
        <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
        <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">trainer</span>
</code></pre></div></div> <h2 id="step-3-full-fine-tuning-sft-dataset">Step 3: Full fine-tuning (SFT dataset)</h2> <p>Next, we train the pre-trained model using SFT (over all the parameters), then calculate the metrics and outputs to evaluate how well it follows instructions.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">utils</span> <span class="kn">import</span> <span class="n">num_trainable_parameters</span>

<span class="n">baseline_training_args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sh">"</span><span class="s">trainer_sft_baseline</span><span class="sh">"</span><span class="p">),</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">epoch</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">logging_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">NUM_EPOCHS</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">fp16</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">(),</span>
    <span class="n">report_to</span><span class="o">=</span><span class="sh">"</span><span class="s">none</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">batch_eval_metrics</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">eval_accumulation_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">base_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">MODEL_NAME_OR_PATH</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Full SFT trainable params: </span><span class="si">{</span><span class="nf">num_trainable_parameters</span><span class="p">(</span><span class="n">base_model</span><span class="p">)</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="n">baseline_trainer</span> <span class="o">=</span> <span class="nf">make_trainer</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">baseline_training_args</span><span class="p">,</span> <span class="n">tokenized_ds_sft</span><span class="p">,</span> <span class="n">compute_metrics</span><span class="p">,</span> <span class="n">data_collator</span><span class="p">)</span>

<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">perf_counter</span><span class="p">()</span>
<span class="n">baseline_trainer</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
<span class="n">baseline_train_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>

<span class="c1"># Save and reload baseline model
</span><span class="n">baseline_trainer</span><span class="p">.</span><span class="nf">save_model</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sh">"</span><span class="s">trainer_sft_baseline</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">finetuned_sft_baseline.model</span><span class="sh">"</span><span class="p">))</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sh">"</span><span class="s">trainer_sft_baseline</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">finetuned_sft_baseline.model</span><span class="sh">"</span><span class="p">)).</span><span class="nf">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">perf_counter</span><span class="p">()</span>
<span class="n">baseline_eval_metrics</span> <span class="o">=</span> <span class="n">baseline_trainer</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">()</span>
<span class="n">baseline_eval_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">t0</span>

<span class="n">baseline_eval_loss</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">baseline_eval_metrics</span><span class="p">[</span><span class="sh">"</span><span class="s">eval_loss</span><span class="sh">"</span><span class="p">])</span>
<span class="n">baseline_rougeL</span> <span class="o">=</span> <span class="n">baseline_eval_metrics</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">eval_rougeL</span><span class="sh">"</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</code></pre></div></div> <details> <summary><b>Hint</b>: Output...</summary> <div style="margin-left: 10px; border-radius: 4px; background: #fff; border: 1px solid black; padding: 10px;"> <pre>
================================================================================
TRAINING BASELINE MODEL (FULL SFT)
================================================================================
Full SFT trainable params: 1484916736
{
  "eval_loss": 1.8790407180786133,
  "eval_rougeL": 0.5532589329689496,
  "eval_runtime": 33.9881,
  "eval_samples_per_second": 11.769,
  "eval_steps_per_second": 11.769,
  "epoch": 2.0
}
</pre> </div> </details> <p>Next, we train the pre-trained model using SFT, then calculate the metrics and outputs to evaluate how well it follows instructions. We also consider how long it will take to fine-tune all the parameters because the next step is to see how LoRA can help us achieve the same level of instruction tuning in less time.</p> <h2 id="step-4-fine-tuning-with-lora">Step 4: Fine-tuning with LoRA</h2> <h3 id="utilities-for-modifying-models">Utilities for modifying models</h3> <p>Define a function <code class="language-plaintext highlighter-rouge">extract_lora_targets</code> that extracts the query and value linear layers from all Transformer blocks in a OLMo model. Return a dictionary that maps the component name to the corresponding linear layer.</p> <details> <summary><b>Hint</b>: How to access the query and value linear layers.</summary> <div style="margin-left: 10px; border-radius: 4px; background: #ddfff0; border: 1px solid black; padding: 5px;"> <p> As we saw earlier, the OLMo model consists of a hierarchy of nested submodules. Each of these can be addressed by a fully-qualified string name. </p> <p> You can use get_submodule() to retrieve a layer by a string name. For instance, <code>'model.layers.layer.0.self_attn.q_proj'</code> refers to the Q part of Transformer layer 0. </p> <p> It's OK to hard-code this part, so that you just enumerate the Q and V parts of all layers here. </p> </div> </details> <p><strong>Sanity check</strong>: If you apply this on a OLMo model, the result should contain 16 named linear layers.</p> <p>We also need a convenience function that puts layers back into a model. The following function does the trick. The <code class="language-plaintext highlighter-rouge">named_layers</code> argument uses the same format as returned by <code class="language-plaintext highlighter-rouge">extract_lora_targets</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">replace_layers</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">named_layers</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Replace submodules in `model` by name.
    </span><span class="sh">"""</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">named_layers</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
        <span class="n">components</span> <span class="o">=</span> <span class="n">name</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">submodule</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">for</span> <span class="n">comp</span> <span class="ow">in</span> <span class="n">components</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">submodule</span> <span class="o">=</span> <span class="nf">getattr</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">comp</span><span class="p">)</span>
        <span class="nf">setattr</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">components</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">layer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div> <h3 id="implementing-the-lora-layer">Implementing the LoRA layer</h3> <p>To implement the LoRA approach, we define a new type of layer that will be used as a drop-in replacement for a regular linear layer.</p> <p>In <a href="https://arxiv.org/pdf/2106.09685" rel="external nofollow noopener" target="_blank">the paper by Hu et al. (2021)</a>, the structure is presented visually in Figure 1, and equation (3) shows the same idea.</p> <p>Start from the following skeleton and fill in the missing pieces:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">LoRALayer</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="c1"># TODO: Add your code here
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># TODO: Replace the next line with your own code
</span>        <span class="k">raise</span> <span class="nb">NotImplementedError</span>
</code></pre></div></div> <p>Here, <code class="language-plaintext highlighter-rouge">W</code> is the linear layer we are fine-tuning, while <code class="language-plaintext highlighter-rouge">r</code> and <code class="language-plaintext highlighter-rouge">alpha</code> are hyperparameters described in section 4.1. of the paper. The <code class="language-plaintext highlighter-rouge">r</code> parameter controls the parameter efficiency: by setting it to a low value, we save memory but make a rougher approximation. The <code class="language-plaintext highlighter-rouge">alpha</code> parameter is a scaling factor.</p> <details> <summary><b>Hint</b>: How to initialize <code>A</code> and <code>B</code>.</summary> <div style="margin-left: 10px; border-radius: 4px; background: #ddfff0; border: 1px solid black; padding: 5px;"> <p> To follow the description closely, we should use the parameter initialization approach recommended in the paper (see Figure 1). </p> <p> You can use <code>nn.init.normal_</code> and <code>nn.init.zeros_</code> here. </p> </div> </details> <h3 id="fine-tuning-with-lora">Fine-tuning with LoRA</h3> <p>Set up a model where you replace the query and value linear layers with LoRA layers. Use the following steps:</p> <ul> <li>First use <code class="language-plaintext highlighter-rouge">extract_lora_targets</code> to get the relevant linear layers.</li> <li>Each of the linear layers in the returned dictionary should be wrapped inside a LoRA layer.</li> <li>Then use <code class="language-plaintext highlighter-rouge">replace_layers</code> to put them back into the model.</li> </ul> <p><strong>Sanity check</strong>: Use your function <code class="language-plaintext highlighter-rouge">num_trainable_parameters</code>. The number of trainable parameters should be less than in Step 1 but more than in Step 2. The exact number will depend on the rank.</p> <p>Train this model and compare the training speed, metrics, and outputs to the results from Steps 1 and 2.</p> <h2 id="side-notes"><strong>Side notes:</strong></h2> <p><strong>Running training on Minerva</strong> When you are ready to perform a full fine-tuning run, submit the provided training job as:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sbatch run.sh <span class="nt">--num-epochs</span> 2 <span class="nt">--output-dir</span> /path/to/runs/baseline
</code></pre></div></div> <p><strong>Running inference on Minerva</strong> To test your fine-tuned or LoRA-adapted checkpoints without re-running training you can run the inference job (omit <code class="language-plaintext highlighter-rouge">--adapter-path</code> to use the base model).</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sbatch predict.sh <span class="nt">--adapter-path</span> /path/to/lora_state_dict.pt <span class="s2">"Summarize ..."</span> <span class="nt">--input</span> <span class="s2">"..."</span>
</code></pre></div></div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?028b9776046506bdc87e88640817bd78"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>