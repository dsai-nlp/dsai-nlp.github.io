<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>DAT450/DIT247: Programming Assignment 5: Retrieval-augmented text generation | NLP@DSAI</title> <meta name="author" content=" "> <meta name="description" content="NLP@DSAI is a constellation of researchers who carry out foundational or applied research in natural language processing (NLP), or are interested in NLP techniques generally. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="stylesheet" href="/assets/css/custom.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dsai-nlp.github.io/courses/dat450/assignment5/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">NLP@DSAI</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">NLP@DSAI</a> </li> <li class="nav-item "> <a class="nav-link" href="/members">Members</a> </li> <li class="nav-item "> <a class="nav-link" href="/events">Events</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/courses/">Courses</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <article> <h1 id="dat450dit247-programming-assignment-5-retrieval-augmented-text-generation">DAT450/DIT247: Programming Assignment 5: Retrieval-augmented text generation</h1> <p>In this assignment we will build our own RAG pipeline using LangChain.</p> <h3 id="pedagogical-purposes-of-this-assignment">Pedagogical purposes of this assignment</h3> <ul> <li>Get an understanding of how RAG can be used within NLP.</li> <li>Learn how to use LangChain to build NLP applications.</li> <li>Get an understanding for the challenges and use cases of RAG.</li> </ul> <h3 id="requirements">Requirements</h3> <p>Please submit your solution in <a href="https://chalmers.instructure.com/courses/31739/assignments/98457" rel="external nofollow noopener" target="_blank">Canvas</a>. <strong>Submission deadline:</strong> December 13.</p> <p>Submit a notebook containing your solution to the programming tasks described below. This is a pure programming assignment and you do not have to write a technical report: there will be a separate individual assignment where you will answer some conceptual questions about what you have been doing here. However, you are welcome to write down your thoughts in this notebook, while you will not be assessed on them here.</p> <h2 id="step-0-get-the-datasets">Step 0: Get the datasets</h2> <p>You will be working with the <a href="https://github.com/pubmedqa/pubmedqa" rel="external nofollow noopener" target="_blank">PubMedQA dataset</a> described in this <a href="https://aclanthology.org/D19-1259.pdf" rel="external nofollow noopener" target="_blank">paper</a>. The dataset has been created based on medical research papers from <a href="https://pubmed.ncbi.nlm.nih.gov/" rel="external nofollow noopener" target="_blank">PubMed</a>, you can read more about it in the linked paper.</p> <p>Use the following code to get the dataset for the assignment.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://raw.githubusercontent.com/pubmedqa/pubmedqa/refs/heads/master/data/ori_pqal.json
</code></pre></div></div> <h3 id="collect-two-datasets-from-the-downloaded-data">Collect two datasets from the downloaded data</h3> <p>We collect two datasets:</p> <ul> <li>‘questions’: the questions with corresponding gold long answer, gold document ID, and year.</li> <li>‘documents’: the abstracts (contexts+long_answer concatenated), and year.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">tmp_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_json</span><span class="p">(</span><span class="sh">"</span><span class="s">/content/ori_pqal.json</span><span class="sh">"</span><span class="p">).</span><span class="n">T</span>
<span class="c1"># some labels have been defined as "maybe", only keep the yes/no answers
</span><span class="n">tmp_data</span> <span class="o">=</span> <span class="n">tmp_data</span><span class="p">[</span><span class="n">tmp_data</span><span class="p">.</span><span class="n">final_decision</span><span class="p">.</span><span class="nf">isin</span><span class="p">([</span><span class="sh">"</span><span class="s">yes</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">no</span><span class="sh">"</span><span class="p">])]</span>

<span class="n">documents</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">abstract</span><span class="sh">"</span><span class="p">:</span> <span class="n">tmp_data</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">).</span><span class="nf">join</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">CONTEXTS</span><span class="o">+</span><span class="p">[</span><span class="n">row</span><span class="p">.</span><span class="n">LONG_ANSWER</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
             <span class="sh">"</span><span class="s">year</span><span class="sh">"</span><span class="p">:</span> <span class="n">tmp_data</span><span class="p">.</span><span class="n">YEAR</span><span class="p">})</span>
<span class="n">questions</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">:</span> <span class="n">tmp_data</span><span class="p">.</span><span class="n">QUESTION</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">year</span><span class="sh">"</span><span class="p">:</span> <span class="n">tmp_data</span><span class="p">.</span><span class="n">YEAR</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">gold_label</span><span class="sh">"</span><span class="p">:</span> <span class="n">tmp_data</span><span class="p">.</span><span class="n">final_decision</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">gold_context</span><span class="sh">"</span><span class="p">:</span> <span class="n">tmp_data</span><span class="p">.</span><span class="n">LONG_ANSWER</span><span class="p">,</span>
             <span class="sh">"</span><span class="s">gold_document_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">documents</span><span class="p">.</span><span class="n">index</span><span class="p">})</span>
</code></pre></div></div> <p>For an example of a query:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">questions</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">question</span>
</code></pre></div></div> <p>For an example of a document to leverage for the queries:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">documents</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">abstract</span>
</code></pre></div></div> <blockquote> <p>Note that we will increase the difficulty of the pipeline in the sense that it needs to find the relevant document on its own. E.g. for question 0 we will not directly give the model abstract 0.</p> </blockquote> <h2 id="step-1-configure-your-langchain-lm">Step 1: Configure your LangChain LM</h2> <p>Define a language model that will act as the generative model in your RAG pipeline. You can for example use the <a href="https://python.langchain.com/docs/integrations/llms/huggingface_pipelines/" rel="external nofollow noopener" target="_blank">HuggingFacePipeline</a> in LangChain to run models on your GPU. You can browse for different Hugging Face models on their <a href="https://huggingface.co/models" rel="external nofollow noopener" target="_blank">webpage</a>. A general guide on how to set up RAG pipelines in LangChain can be found <a href="https://python.langchain.com/v0.1/docs/use_cases/chatbots/retrieval/#creating-a-retriever" rel="external nofollow noopener" target="_blank">here</a>.</p> <blockquote> <p>You should be able to fit a model of at least a size of 1B parameters on the T4 GPUs available in Colab.</p> </blockquote> <blockquote> <p>Some interesting models (e.g. Llama 3.2) may require that you apply for access. This process is usually quite fast, while it may require that you create an account on Hugging Face (it is free). To use a gated model you need to generate a personal HF token and put it as a secret in your notebook (if using Colab). Make sure that the token has enabled “Read access to contents of all public gated repos you can access”.</p> </blockquote> <p><strong>Sanity check:</strong> Prompt your LangChain model and confirm that it returns a reasonable output.</p> <h2 id="step-2-set-up-the-document-database-and-retriever">Step 2: Set up the document database and retriever</h2> <h3 id="step-21-embedding-model">Step 2.1: Embedding model</h3> <p>First, you need a model to embed the documents in the retrieval corpus. Here, we recommend using the <a href="https://api.python.langchain.com/en/latest/huggingface/embeddings/langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings.html" rel="external nofollow noopener" target="_blank">HuggingFaceEmbeddings</a> function.</p> <p><strong>Sanity check:</strong> Pass a text passage to the embedding model and evaluate its shape. It should be of the shape (1, embedding_dim).</p> <h3 id="step-22-chunking">Step 2.2: Chunking</h3> <p>Second, you need to chunk the documents in your retrieval corpus, as some likely are too long for the embedding model. Here, you can use the <a href="https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/" rel="external nofollow noopener" target="_blank">RecursiveCharacterTextSplitter</a> as a start. The retrieval corpus is given by <code class="language-plaintext highlighter-rouge">documents.abstract</code>.</p> <p><strong>Sanity check:</strong> Print some samples from the result and check that it makes sense. This way, you might be able to get a feeling for a good chunk size.</p> <h3 id="step-23-define-a-vector-store-and-retriever">Step 2.3: Define a vector store and retriever</h3> <p>Third, you need a vector store to store the documents and corresponding embeddings (indeces). There are many document databases and retrievers to play around with. As a start, you can use the <a href="https://python.langchain.com/docs/integrations/vectorstores/chroma/" rel="external nofollow noopener" target="_blank">Chroma</a> vector store with cosine similarity as the distance metric. You can then define the retriever using something like the following:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">retriever</span> <span class="o">=</span> <span class="n">vector_store</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">(...)</span>
</code></pre></div></div> <p>As a start, you might want the retriever to fetch only one document per prompt.</p> <p><strong>Sanity check:</strong> Query your vector store as follows and check that the results make sense:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="n">vector_store</span><span class="p">.</span><span class="nf">similarity_search_with_score</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">What is programmed cell death?</span><span class="sh">"</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">res</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">* [SIM=</span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">] </span><span class="si">{</span><span class="n">res</span><span class="p">.</span><span class="n">page_content</span><span class="si">}</span><span class="s"> [</span><span class="si">{</span><span class="n">res</span><span class="p">.</span><span class="n">metadata</span><span class="si">}</span><span class="s">]</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="step-3-define-the-full-rag-pipeline">Step 3: Define the full RAG pipeline</h2> <p>We are now ready to combine all previously defined components into a complete RAG pipeline. Define a prompt and set up your chain with the retriever and generator LM. Here, you might want to define a chain that also returns what document was retrieved, the <a href="https://python.langchain.com/v0.1/docs/expression_language/primitives/parallel/" rel="external nofollow noopener" target="_blank">RunnableParallel</a> function can be used for this.</p> <p><strong>Sanity check:</strong> Take a question from your dataset and check whether the model seems to retrieve a relevant document, and answer in a reasonable fashion.</p> <h2 id="step-4-evaluate-the-rag-pipeline-on-the-dataset">Step 4: Evaluate the RAG pipeline on the dataset</h2> <ul> <li>Evaluate your full RAG pipeline on the medical questions (<code class="language-plaintext highlighter-rouge">questions.question</code>) and corresponding gold labels (<code class="language-plaintext highlighter-rouge">questions.gold_label</code>). Since the gold labels can be casted to a binary variable (yes/no) you may use the f1 metric.</li> <li>Also evaluate your retriever by checking whether it managed to fetch passages from the gold document with ID given by <code class="language-plaintext highlighter-rouge">questions.gold_document_id</code>.</li> <li>As a baseline, run the same LM without context and compare the performance of the two setups. Did the retrieval help?</li> <li>Also, inspect some retrieved documents and corresponding model answers. Does the pipeline seem to work as intended?</li> </ul> <h2 id="step-5-make-improvements">Step 5: Make improvements</h2> <p>After having observed the performance of your pipeline, you might have some ideas on how to improve it. Thanks to the abstraction level in LangChain, it should be quite easy to experiment with different improvements. Experiment with at least two types of improvements to your RAG pipeline that you find interesting. Make sure to document your experiments and the corresponding results.</p> <p>Aspects that can be tinkered with are for example:</p> <ul> <li>the document chunker: some alternatives can be found <a href="https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/" rel="external nofollow noopener" target="_blank">here</a>,</li> <li>prompt: a guide on prompt tuning can be found <a href="https://www.pinecone.io/learn/series/langchain/langchain-prompt-templates/" rel="external nofollow noopener" target="_blank">here</a>,</li> <li>retriever: some alternatives can be found <a href="https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/" rel="external nofollow noopener" target="_blank">here</a>,</li> <li>embedding model: some alternatives can be found <a href="https://python.langchain.com/docs/integrations/text_embedding/" rel="external nofollow noopener" target="_blank">here</a>,</li> <li>etc…</li> </ul> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>